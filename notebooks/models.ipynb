{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542d3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from classes import MixedNaiveBayes\n",
    "\n",
    "from classes import CustomLogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from helpers import cv_evaluate_model\n",
    "\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bf0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "(train_X_folds, train_y_folds, test_X_folds, test_y_folds, feature_names_folds, reverse_map_folds, k_fold_split) = pickle.load(open('data/prepared_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa577cb",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b9d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline ===\n",
      "Training Logistic Regression with L1 & L2 regularization...\n",
      "Trained fold 0 in 5.22s\n",
      "Trained fold 1 in 6.18s\n",
      "Trained fold 2 in 5.94s\n",
      "Trained fold 3 in 5.39s\n",
      "Trained fold 4 in 5.27s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline ===\")\n",
    "\n",
    "alpha = 10.0\n",
    "l1_ratio = 0.75\n",
    "\n",
    "# Train Logistic Regression with L1 & L2 regularization\n",
    "print(\"Training Logistic Regression with L1 & L2 regularization...\")\n",
    "\n",
    "logistic_regression_results = cv_evaluate_model(\n",
    "    lambda: CustomLogisticRegression(\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=1000,\n",
    "        tol=1e-6,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d56f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance Analysis\n",
      "\n",
      "Average training time: 5.60s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6601\n",
      "Avg Precision:  0.1811\n",
      "Avg Recall:     0.5807\n",
      "Avg F1:         0.2760\n",
      "Avg ROC AUC:    0.6757\n",
      "Avg PR AUC:     0.2114\n",
      "Overfitting Accuracy: 0.0030\n",
      "Overfitting AUC: 0.0138\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12117           5992           \n",
      "                Readmit         1001            1324           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                         -3.544379\n",
      "discharge_disposition_id_28                          1.409278\n",
      "discharge_disposition_id_22                          1.322310\n",
      "discharge_disposition_id_5                           0.998582\n",
      "discharge_disposition_id_15                          0.751023\n",
      "discharge_disposition_id_13                         -0.734342\n",
      "discharge_disposition_id_14                         -0.567374\n",
      "discharge_disposition_id_2                           0.544543\n",
      "discharge_disposition_id_23                         -0.539434\n",
      "medical_specialty_Hematology/Oncology                0.525348\n",
      "diag_PC19                                            0.481611\n",
      "diag_PC129                                          -0.480690\n",
      "medical_specialty_Surgery-Cardiovascular/Thoracic   -0.468698\n",
      "medical_specialty_ObstetricsandGynecology           -0.416932\n",
      "diag_PC143                                           0.398127\n",
      "gender_Male x age_[20-30)                           -0.380996\n",
      "medical_specialty_Hematology                         0.379568\n",
      "diag_PC43                                           -0.372406\n",
      "discharge_disposition_id_3                           0.371942\n",
      "diag_PC35                                            0.341732\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {logistic_regression_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {logistic_regression_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {logistic_regression_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {logistic_regression_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {logistic_regression_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {logistic_regression_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {logistic_regression_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {logistic_regression_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {logistic_regression_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = logistic_regression_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "feature_importance = pd.Series(logistic_regression_results[\"results\"][0][\"model\"].coef_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0ff8c",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f144e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "Training MixedNaiveBayes with balanced classes...\n",
      "Trained fold 0 in 1.18s\n",
      "Trained fold 1 in 1.05s\n",
      "Trained fold 2 in 1.13s\n",
      "Trained fold 3 in 1.14s\n",
      "Trained fold 4 in 1.08s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Naive Bayes ===\")\n",
    "\n",
    "# Train MixedNaiveBayes with balanced classes using cv_evaluate_model format\n",
    "print(\"Training MixedNaiveBayes with balanced classes...\")\n",
    "\n",
    "naive_bayes_results = cv_evaluate_model(\n",
    "    lambda: MixedNaiveBayes(class_weight='balanced'),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372e991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance Analysis\n",
      "\n",
      "Average training time: 1.12s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6199\n",
      "Avg Precision:  0.1446\n",
      "Avg Recall:     0.4888\n",
      "Avg F1:         0.2231\n",
      "Avg ROC AUC:    0.5878\n",
      "Avg PR AUC:     0.1544\n",
      "Overfitting Accuracy: 0.0026\n",
      "Overfitting AUC: 0.0153\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11473           6636           \n",
      "                Readmit         1154            1171           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                 -0.065009\n",
      "insulin_yes                                  0.026994\n",
      "admission_source_id_7                        0.017168\n",
      "discharge_disposition_id_22                 -0.010460\n",
      "metformin_yes                               -0.008313\n",
      "age_[50-60)                                 -0.005458\n",
      "medical_specialty_Cardiology                -0.003493\n",
      "age_[70-80)                                  0.003474\n",
      "admission_type_id_3                         -0.003086\n",
      "discharge_disposition_id_5                  -0.002910\n",
      "age_[80-90)                                  0.002342\n",
      "medical_specialty_ObstetricsandGynecology   -0.002163\n",
      "diag_PC66                                    0.002122\n",
      "diag_PC67                                    0.002122\n",
      "diag_PC68                                    0.002122\n",
      "diag_PC65                                    0.002122\n",
      "diag_PC64                                    0.002122\n",
      "diag_PC63                                    0.002122\n",
      "diag_PC70                                    0.002122\n",
      "diag_PC62                                    0.002122\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {naive_bayes_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {naive_bayes_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {naive_bayes_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {naive_bayes_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {naive_bayes_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {naive_bayes_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {naive_bayes_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {naive_bayes_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {naive_bayes_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = naive_bayes_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Naive Bayes using log likelihood\n",
    "print(f\"\\nMost Important Features:\")\n",
    "model = naive_bayes_results[\"results\"][0][\"model\"]\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Get log likelihood for each feature\n",
    "log_likelihood = model.get_log_likelihood(train_X_first_fold)\n",
    "\n",
    "# Calculate feature importance as the difference in log likelihood between classes\n",
    "# Positive values indicate features that favor class 1 (readmission)\n",
    "feature_importance_values = log_likelihood[:, 1] - log_likelihood[:, 0]\n",
    "\n",
    "# Create pandas Series for consistent format\n",
    "feature_importance = pd.Series(feature_importance_values, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d868c9c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62324bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear SVM ===\n",
      "Training SGDClassifier with hinge loss (Linear SVM)...\n",
      "Trained fold 0 in 6.96s\n",
      "Trained fold 1 in 4.29s\n",
      "Trained fold 2 in 3.47s\n",
      "Trained fold 3 in 4.31s\n",
      "Trained fold 4 in 5.09s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Linear SVM ===\")\n",
    "\n",
    "# Train SGDClassifier with hinge loss (equivalent to SVM) using cv_evaluate_model format\n",
    "print(\"Training SGDClassifier with hinge loss (Linear SVM)...\")\n",
    "\n",
    "linear_svm_results = cv_evaluate_model(\n",
    "    lambda: SGDClassifier(\n",
    "        loss='hinge',           # Hinge loss = SVM\n",
    "        max_iter=1000,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        learning_rate='optimal'\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77ff1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Model Performance Analysis\n",
      "\n",
      "Average training time: 4.83s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6536\n",
      "Avg Precision:  0.1778\n",
      "Avg Recall:     0.5800\n",
      "Avg F1:         0.2720\n",
      "Avg ROC AUC:    0.6686\n",
      "Avg PR AUC:     0.2069\n",
      "Overfitting Accuracy: 0.0041\n",
      "Overfitting AUC: 0.0174\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12496           5613           \n",
      "                Readmit         1056            1269           \n",
      "\n",
      "Most Important Features (Std-Adjusted):\n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.494645\n",
      "discharge_disposition_id_11   -0.303617\n",
      "discharge_disposition_id_22    0.233930\n",
      "discharge_disposition_id_3     0.227592\n",
      "discharge_disposition_id_5     0.158642\n",
      "diag_PC7                       0.128290\n",
      "diag_PC1                       0.123597\n",
      "discharge_disposition_id_2     0.119308\n",
      "diag_PC19                      0.112456\n",
      "age_[80-90)                    0.107065\n",
      "discharge_disposition_id_6     0.099763\n",
      "admission_source_id_17        -0.098744\n",
      "gender_Male x age_[60-70)      0.081875\n",
      "discharge_disposition_id_18    0.076018\n",
      "time_in_hospital               0.075324\n",
      "age_[60-70)                    0.072510\n",
      "diag_PC40                      0.065571\n",
      "discharge_disposition_id_28    0.062264\n",
      "diag_PC35                      0.061129\n",
      "A1Cresult_>8                  -0.060611\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {linear_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {linear_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {linear_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {linear_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {linear_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {linear_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {linear_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {linear_svm_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {linear_svm_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = linear_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Linear SVM (adjusted by standard deviation)\n",
    "print(f\"\\nMost Important Features (Std-Adjusted):\")\n",
    "\n",
    "# Get the first fold data for standard deviation calculation\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Calculate standard deviation for each feature\n",
    "feature_std = np.std(train_X_first_fold, axis=0)\n",
    "\n",
    "# Get raw coefficients\n",
    "raw_coef = linear_svm_results[\"results\"][0][\"model\"].coef_[0]\n",
    "\n",
    "# Calculate adjusted feature importance: coefficient * std_dev (preserve direction)\n",
    "feature_importance_with_direction = raw_coef * feature_std\n",
    "\n",
    "# Create pandas Series for consistent format with baseline\n",
    "feature_importance = pd.Series(feature_importance_with_direction, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d469185",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1969dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RFF Kernel SVM (Random Fourier Features) ===\n",
      "Training RFF with SGD hinge loss (RBF kernel approximation)...\n",
      "Trained fold 0 in 20.26s\n",
      "Trained fold 1 in 15.44s\n",
      "Trained fold 2 in 16.63s\n",
      "Trained fold 3 in 17.87s\n",
      "Trained fold 4 in 16.11s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RFF Kernel SVM (Random Fourier Features) ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "gamma = 0.01  # RBF kernel parameter\n",
    "n_components = 2000  # Number of random features\n",
    "\n",
    "# Train RFF with SGD hinge loss (approximation to RBF kernel SVM)\n",
    "print(\"Training RFF with SGD hinge loss (RBF kernel approximation)...\")\n",
    "\n",
    "rff_svm_results = cv_evaluate_model(\n",
    "    lambda: Pipeline([\n",
    "        ('rff', RBFSampler(gamma=gamma, n_components=n_components, random_state=seed)),\n",
    "        ('sgd', SGDClassifier(\n",
    "            loss='hinge',\n",
    "            max_iter=1000,\n",
    "            random_state=seed,\n",
    "            class_weight='balanced',\n",
    "            learning_rate='optimal'\n",
    "        ))\n",
    "    ]),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1996ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF SVM Model Performance Analysis\n",
      "\n",
      "Average training time: 17.26s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6743\n",
      "Avg Precision:  0.1803\n",
      "Avg Recall:     0.5393\n",
      "Avg F1:         0.2699\n",
      "Avg ROC AUC:    0.6650\n",
      "Avg PR AUC:     0.2002\n",
      "Overfitting Accuracy: 0.0022\n",
      "Overfitting AUC: 0.0107\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12973           5136           \n",
      "                Readmit         1173            1152           \n",
      "Note: RFF approximates RBF kernel with random Fourier features for faster training\n"
     ]
    }
   ],
   "source": [
    "print(\"RFF SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {rff_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {rff_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {rff_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {rff_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {rff_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {rff_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {rff_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {rff_svm_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {rff_svm_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = rff_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "print(\"Note: RFF approximates RBF kernel with random Fourier features for faster training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646cf1e8",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209ae27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "Training Decision Tree with balanced classes...\n",
      "Trained fold 0 in 7.92s\n",
      "Trained fold 1 in 8.62s\n",
      "Trained fold 2 in 8.13s\n",
      "Trained fold 3 in 8.18s\n",
      "Trained fold 4 in 8.39s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Decision Tree ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "max_depth = 5  # Will be optimized in finetuning\n",
    "min_samples_split = 200  # Will be optimized in finetuning\n",
    "min_samples_leaf = 100  # Will be optimized in finetuning\n",
    "max_features = None  # Will be optimized in finetuning\n",
    "\n",
    "# Train Decision Tree with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Decision Tree with balanced classes...\")\n",
    "\n",
    "decision_tree_results = cv_evaluate_model(\n",
    "    lambda: DecisionTreeClassifier(\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461ad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance Analysis\n",
      "\n",
      "Average training time: 8.25s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6367\n",
      "Avg Precision:  0.1706\n",
      "Avg Recall:     0.5838\n",
      "Avg F1:         0.2640\n",
      "Avg ROC AUC:    0.6478\n",
      "Avg PR AUC:     0.2043\n",
      "Overfitting Accuracy: 0.0014\n",
      "Overfitting AUC: 0.0064\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11463           6646           \n",
      "                Readmit         950             1375           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               5.791732e-01\n",
      "discharge_disposition_id_22    1.179520e-01\n",
      "discharge_disposition_id_11    1.005952e-01\n",
      "discharge_disposition_id_3     7.479172e-02\n",
      "diag_PC1                       5.943218e-02\n",
      "discharge_disposition_id_5     2.102627e-02\n",
      "diag_PC10                      7.142425e-03\n",
      "diag_PC87                      5.403868e-03\n",
      "diag_PC20                      5.354703e-03\n",
      "diag_PC59                      4.676635e-03\n",
      "diag_PC22                      4.310883e-03\n",
      "diag_PC30                      4.303016e-03\n",
      "diag_PC0                       3.479581e-03\n",
      "diag_PC171                     3.254052e-03\n",
      "diag_PC153                     2.993184e-03\n",
      "diag_PC151                     2.489885e-03\n",
      "diag_PC147                     2.025589e-03\n",
      "diag_PC11                      1.595536e-03\n",
      "diag_PC125                     5.513447e-13\n",
      "diag_PC55                      0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {decision_tree_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {decision_tree_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {decision_tree_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {decision_tree_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {decision_tree_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {decision_tree_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {decision_tree_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {decision_tree_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {decision_tree_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = decision_tree_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(decision_tree_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa0211",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e765764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Training Random Forest with balanced classes...\n",
      "Trained fold 0 in 28.26s\n",
      "Trained fold 1 in 25.73s\n",
      "Trained fold 2 in 29.81s\n",
      "Trained fold 3 in 30.76s\n",
      "Trained fold 4 in 32.26s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Random Forest ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 200  # Will be optimized in finetuning\n",
    "max_depth = 9  # Will be optimized in finetuning\n",
    "min_samples_split = 200  # Will be optimized in finetuning\n",
    "min_samples_leaf = 100  # Will be optimized in finetuning\n",
    "max_features = 'sqrt'  # Will be optimized in finetuning\n",
    "\n",
    "# Train Random Forest with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Random Forest with balanced classes...\")\n",
    "\n",
    "random_forest_results = cv_evaluate_model(\n",
    "    lambda: RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight='balanced',\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "719763bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance Analysis\n",
      "\n",
      "Average training time: 29.37\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6848\n",
      "Avg Precision:  0.1775\n",
      "Avg Recall:     0.5022\n",
      "Avg F1:         0.2623\n",
      "Avg ROC AUC:    0.6528\n",
      "Avg PR AUC:     0.1907\n",
      "Overfitting Accuracy: 0.0274\n",
      "Overfitting AUC: 0.0935\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12634           5475           \n",
      "                Readmit         1148            1177           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.138247\n",
      "discharge_disposition_id_11    0.029410\n",
      "diag_PC1                       0.029248\n",
      "discharge_disposition_id_22    0.028238\n",
      "number_emergency               0.019479\n",
      "diag_PC0                       0.016825\n",
      "number_diagnoses               0.014534\n",
      "num_medications                0.012450\n",
      "diag_PC7                       0.012206\n",
      "diag_PC18                      0.010790\n",
      "discharge_disposition_id_3     0.010530\n",
      "diag_PC5                       0.010506\n",
      "time_in_hospital               0.010253\n",
      "diag_PC19                      0.009485\n",
      "diag_PC27                      0.008245\n",
      "diag_PC16                      0.008006\n",
      "diag_PC68                      0.007066\n",
      "diag_PC72                      0.006688\n",
      "diag_PC143                     0.005973\n",
      "diag_PC4                       0.005899\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {random_forest_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {random_forest_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {random_forest_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {random_forest_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {random_forest_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {random_forest_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {random_forest_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {random_forest_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {random_forest_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = random_forest_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(random_forest_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b3ffe",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6869f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Training XGBoost with balanced classes...\n",
      "Trained fold 0 in 3.76s\n",
      "Trained fold 1 in 3.63s\n",
      "Trained fold 2 in 3.80s\n",
      "Trained fold 3 in 3.28s\n",
      "Trained fold 4 in 3.45s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== XGBoost ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 200  \n",
    "max_depth = 4\n",
    "learning_rate = 0.1 \n",
    "subsample = 1.0\n",
    "colsample_bytree = 1.0\n",
    "\n",
    "# Train XGBoost with balanced classes using cv_evaluate_model format\n",
    "print(\"Training XGBoost with balanced classes...\")\n",
    "\n",
    "xgb_results = cv_evaluate_model(\n",
    "    lambda: xgb.XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        scale_pos_weight=len(train_y_folds[0][train_y_folds[0]==0])/len(train_y_folds[0][train_y_folds[0]==1]),  # Handle class imbalance\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d4af325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance Analysis\n",
      "\n",
      "Average training time: 3.58\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6783\n",
      "Avg Precision:  0.1843\n",
      "Avg Recall:     0.5488\n",
      "Avg F1:         0.2758\n",
      "Avg ROC AUC:    0.6717\n",
      "Avg PR AUC:     0.2193\n",
      "Overfitting Accuracy: 0.0272\n",
      "Overfitting AUC: 0.0979\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12601           5508           \n",
      "                Readmit         1063            1262           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.042081\n",
      "discharge_disposition_id_22    0.021406\n",
      "discharge_disposition_id_3     0.019392\n",
      "discharge_disposition_id_11    0.012461\n",
      "diag_PC1                       0.010166\n",
      "admission_type_id_3            0.009642\n",
      "discharge_disposition_id_5     0.009424\n",
      "diag_PC141                     0.006912\n",
      "number_diagnoses               0.006767\n",
      "discharge_disposition_id_2     0.006299\n",
      "diag_PC45                      0.006232\n",
      "admission_type_id_2            0.005954\n",
      "diag_PC7                       0.005893\n",
      "diag_PC43                      0.005746\n",
      "diag_PC74                      0.005583\n",
      "time_in_hospital               0.005513\n",
      "diag_PC35                      0.005348\n",
      "diag_PC145                     0.005317\n",
      "discharge_disposition_id_28    0.004996\n",
      "diag_PC27                      0.004917\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {xgb_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {xgb_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {xgb_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {xgb_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {xgb_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {xgb_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {xgb_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {xgb_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {xgb_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = xgb_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(xgb_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc9b04",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc536d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Comparison Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>Overfitting Acc</th>\n",
       "      <th>Overfitting AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5.599105</td>\n",
       "      <td>0.660070</td>\n",
       "      <td>0.181064</td>\n",
       "      <td>0.580709</td>\n",
       "      <td>0.276027</td>\n",
       "      <td>0.675686</td>\n",
       "      <td>0.211393</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.013802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1.117618</td>\n",
       "      <td>0.619935</td>\n",
       "      <td>0.144602</td>\n",
       "      <td>0.488756</td>\n",
       "      <td>0.223074</td>\n",
       "      <td>0.587833</td>\n",
       "      <td>0.154446</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.015294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>4.825053</td>\n",
       "      <td>0.653565</td>\n",
       "      <td>0.177796</td>\n",
       "      <td>0.580020</td>\n",
       "      <td>0.272037</td>\n",
       "      <td>0.668573</td>\n",
       "      <td>0.206887</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.017443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVM</td>\n",
       "      <td>17.260378</td>\n",
       "      <td>0.674337</td>\n",
       "      <td>0.180277</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.269877</td>\n",
       "      <td>0.664965</td>\n",
       "      <td>0.200175</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.010716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>8.247960</td>\n",
       "      <td>0.636725</td>\n",
       "      <td>0.170579</td>\n",
       "      <td>0.583801</td>\n",
       "      <td>0.263993</td>\n",
       "      <td>0.647820</td>\n",
       "      <td>0.204315</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>29.365206</td>\n",
       "      <td>0.684776</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>0.502223</td>\n",
       "      <td>0.262297</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.190662</td>\n",
       "      <td>0.027428</td>\n",
       "      <td>0.093529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3.583205</td>\n",
       "      <td>0.678270</td>\n",
       "      <td>0.184252</td>\n",
       "      <td>0.548798</td>\n",
       "      <td>0.275815</td>\n",
       "      <td>0.671737</td>\n",
       "      <td>0.219269</td>\n",
       "      <td>0.027156</td>\n",
       "      <td>0.097870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Time (s)  Accuracy  Precision    Recall  \\\n",
       "0  Logistic Regression           5.599105  0.660070   0.181064  0.580709   \n",
       "1          Naive Bayes           1.117618  0.619935   0.144602  0.488756   \n",
       "2           Linear SVM           4.825053  0.653565   0.177796  0.580020   \n",
       "3           Kernel SVM          17.260378  0.674337   0.180277  0.539319   \n",
       "4        Decision Tree           8.247960  0.636725   0.170579  0.583801   \n",
       "5        Random Forest          29.365206  0.684776   0.177534  0.502223   \n",
       "6              XGBoost           3.583205  0.678270   0.184252  0.548798   \n",
       "\n",
       "   F1 Score   ROC AUC    PR AUC  Overfitting Acc  Overfitting AUC  \n",
       "0  0.276027  0.675686  0.211393         0.003034         0.013802  \n",
       "1  0.223074  0.587833  0.154446         0.002617         0.015294  \n",
       "2  0.272037  0.668573  0.206887         0.004067         0.017443  \n",
       "3  0.269877  0.664965  0.200175         0.002184         0.010716  \n",
       "4  0.263993  0.647820  0.204315         0.001390         0.006404  \n",
       "5  0.262297  0.652826  0.190662         0.027428         0.093529  \n",
       "6  0.275815  0.671737  0.219269         0.027156         0.097870  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison table with all model results\n",
    "print(\"=== Model Comparison Table ===\")\n",
    "\n",
    "# Collect all results\n",
    "models_data = {\n",
    "    'Logistic Regression': logistic_regression_results,\n",
    "    'Naive Bayes': naive_bayes_results,\n",
    "    'Linear SVM': linear_svm_results,\n",
    "    'Kernel SVM': rff_svm_results,\n",
    "    'Decision Tree': decision_tree_results,\n",
    "    'Random Forest': random_forest_results,\n",
    "    'XGBoost': xgb_results\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame with numeric values for better analysis\n",
    "comparison_data = []\n",
    "for model_name, results in models_data.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Training Time (s)': results['training_time'][0],\n",
    "        'Accuracy': results['test_accuracy'][0],\n",
    "        'Precision': results['test_precision_score'][0],\n",
    "        'Recall': results['test_recall_score'][0],\n",
    "        'F1 Score': results['test_f1'][0],\n",
    "        'ROC AUC': results['test_roc_auc'][0],\n",
    "        'PR AUC': results['test_pr_auc'][0],\n",
    "        'Overfitting Acc': results['overfitting_accuracy'][0],\n",
    "        'Overfitting AUC': results['overfitting_auc'][0]\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e86bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Performance Analysis ===\n",
      "\n",
      "==================================================\n",
      "BEST PERFORMING MODELS:\n",
      "==================================================\n",
      "Accuracy    : Random Forest        (0.6848)\n",
      "Precision   : XGBoost              (0.1843)\n",
      "Recall      : Decision Tree        (0.5838)\n",
      "F1 Score    : Logistic Regression  (0.2760)\n",
      "ROC AUC     : Logistic Regression  (0.6757)\n",
      "PR AUC      : XGBoost              (0.2193)\n",
      "\n",
      "==================================================\n",
      "OVERFITTING ANALYSIS:\n",
      "==================================================\n",
      "Overfitting Acc: Random Forest        (0.0274) - HIGHER IS WORSE\n",
      "Overfitting AUC: XGBoost              (0.0979) - HIGHER IS WORSE\n",
      "\n",
      "==================================================\n",
      "TRAINING TIME ANALYSIS:\n",
      "==================================================\n",
      "Fastest Training: Naive Bayes          (1.12s)\n",
      "Slowest Training: Random Forest        (29.37s)\n",
      "\n",
      "==================================================\n",
      "RANKING BY ROC AUC (Best to Worst):\n",
      "==================================================\n",
      "Logistic Regression : 0.6757\n",
      "XGBoost             : 0.6717\n",
      "Linear SVM          : 0.6686\n",
      "Kernel SVM          : 0.6650\n",
      "Random Forest       : 0.6528\n",
      "Decision Tree       : 0.6478\n",
      "Naive Bayes         : 0.5878\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the comparison results\n",
    "print(\"=== Model Performance Analysis ===\")\n",
    "\n",
    "# Find best performing models for each metric\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BEST PERFORMING MODELS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Since comparison_df now has numeric values, we can work directly with it\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC']:\n",
    "    best_idx = comparison_df[metric].idxmax()\n",
    "    best_model = comparison_df.loc[best_idx, 'Model']\n",
    "    best_score = comparison_df.loc[best_idx, metric]\n",
    "    print(f\"{metric:<12}: {best_model:<20} ({best_score:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"OVERFITTING ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "# For overfitting, we want the HIGHEST values (most overfitting)\n",
    "for metric in ['Overfitting Acc', 'Overfitting AUC']:\n",
    "    worst_idx = comparison_df[metric].idxmax()  # Use idxmax for overfitting (higher is worse)\n",
    "    worst_model = comparison_df.loc[worst_idx, 'Model']\n",
    "    worst_score = comparison_df.loc[worst_idx, metric]\n",
    "    print(f\"{metric:<12}: {worst_model:<20} ({worst_score:.4f}) - HIGHER IS WORSE\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING TIME ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "fastest_idx = comparison_df['Training Time (s)'].idxmin()\n",
    "fastest_model = comparison_df.loc[fastest_idx, 'Model']\n",
    "fastest_time = comparison_df.loc[fastest_idx, 'Training Time (s)']\n",
    "print(f\"Fastest Training: {fastest_model:<20} ({fastest_time:.2f}s)\")\n",
    "\n",
    "slowest_idx = comparison_df['Training Time (s)'].idxmax()\n",
    "slowest_model = comparison_df.loc[slowest_idx, 'Model']\n",
    "slowest_time = comparison_df.loc[slowest_idx, 'Training Time (s)']\n",
    "print(f\"Slowest Training: {slowest_model:<20} ({slowest_time:.2f}s)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RANKING BY ROC AUC (Best to Worst):\")\n",
    "print(\"=\" * 50)\n",
    "roc_ranking = comparison_df.sort_values('ROC AUC', ascending=False)[['Model', 'ROC AUC']]\n",
    "for idx, row in roc_ranking.iterrows():\n",
    "    print(f\"{row['Model']:<20}: {row['ROC AUC']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acb32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it5006-group10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
