{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542d3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from classes import MixedNaiveBayes\n",
    "\n",
    "from classes import CustomLogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from helpers import cv_evaluate_model\n",
    "\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bf0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "(train_X_folds, train_y_folds, test_X_folds, test_y_folds, feature_names_folds, reverse_map_folds) = pickle.load(open('data/prepared_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa577cb",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7b9d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline ===\n",
      "Training Logistic Regression with L1 & L2 regularization...\n",
      "Trained fold 0 in 7.83s\n",
      "Trained fold 1 in 6.92s\n",
      "Trained fold 2 in 7.50s\n",
      "Trained fold 3 in 6.75s\n",
      "Trained fold 4 in 6.91s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline ===\")\n",
    "\n",
    "alpha = 5\n",
    "l1_ratio = 0.75\n",
    "\n",
    "# Train Logistic Regression with L1 & L2 regularization\n",
    "print(\"Training Logistic Regression with L1 & L2 regularization...\")\n",
    "\n",
    "logistic_regression_results = cv_evaluate_model(\n",
    "    lambda: CustomLogisticRegression(\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=1000,\n",
    "        tol=1e-6,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d56f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance Analysis\n",
      "\n",
      "Average training time: 7.18s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6582\n",
      "Avg Precision:  0.1800\n",
      "Avg Recall:     0.5801\n",
      "Avg F1:         0.2747\n",
      "Avg ROC AUC:    0.6745\n",
      "Avg PR AUC:     0.2111\n",
      "Overfitting Accuracy: 0.0037\n",
      "Overfitting AUC: 0.0168\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12089           6020           \n",
      "                Readmit         994             1331           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                  -4.215332\n",
      "discharge_disposition_id_28                   1.689171\n",
      "discharge_disposition_id_15                   1.364386\n",
      "discharge_disposition_id_22                   1.351553\n",
      "discharge_disposition_id_5                    1.030752\n",
      "discharge_disposition_id_13                  -0.809176\n",
      "medical_specialty_Otolaryngology             -0.775223\n",
      "medical_specialty_Pediatrics-Endocrinology   -0.770679\n",
      "medical_specialty_Hematology                  0.749855\n",
      "discharge_disposition_id_9                    0.670702\n",
      "discharge_disposition_id_14                  -0.659517\n",
      "medical_specialty_Hematology/Oncology         0.597548\n",
      "discharge_disposition_id_23                  -0.594647\n",
      "diag_PC173                                   -0.586729\n",
      "race_Other x age_[80-90)                     -0.586537\n",
      "discharge_disposition_id_2                    0.556056\n",
      "race_Asian x age_[70-80)                      0.541512\n",
      "diag_PC129                                   -0.526060\n",
      "diag_PC187                                   -0.514839\n",
      "diag_PC19                                     0.499054\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {logistic_regression_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {logistic_regression_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {logistic_regression_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {logistic_regression_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {logistic_regression_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {logistic_regression_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {logistic_regression_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {logistic_regression_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {logistic_regression_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = logistic_regression_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "feature_importance = pd.Series(logistic_regression_results[\"results\"][0][\"model\"].coef_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0ff8c",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f144e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "Training MixedNaiveBayes with balanced classes...\n",
      "Trained fold 0 in 1.03s\n",
      "Trained fold 1 in 0.96s\n",
      "Trained fold 2 in 1.03s\n",
      "Trained fold 3 in 0.98s\n",
      "Trained fold 4 in 1.12s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Naive Bayes ===\")\n",
    "\n",
    "# Train MixedNaiveBayes with balanced classes using cv_evaluate_model format\n",
    "print(\"Training MixedNaiveBayes with balanced classes...\")\n",
    "\n",
    "naive_bayes_results = cv_evaluate_model(\n",
    "    lambda: MixedNaiveBayes(class_weight='balanced'),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372e991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance Analysis\n",
      "\n",
      "Average training time: 1.02s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6199\n",
      "Avg Precision:  0.1446\n",
      "Avg Recall:     0.4888\n",
      "Avg F1:         0.2231\n",
      "Avg ROC AUC:    0.5878\n",
      "Avg PR AUC:     0.1544\n",
      "Overfitting Accuracy: 0.0026\n",
      "Overfitting AUC: 0.0153\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11473           6636           \n",
      "                Readmit         1154            1171           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                 -0.065009\n",
      "insulin_yes                                  0.026994\n",
      "admission_source_id_7                        0.017168\n",
      "discharge_disposition_id_22                 -0.010460\n",
      "metformin_yes                               -0.008313\n",
      "age_[50-60)                                 -0.005458\n",
      "medical_specialty_Cardiology                -0.003493\n",
      "age_[70-80)                                  0.003474\n",
      "admission_type_id_3                         -0.003086\n",
      "discharge_disposition_id_5                  -0.002910\n",
      "age_[80-90)                                  0.002342\n",
      "medical_specialty_ObstetricsandGynecology   -0.002163\n",
      "diag_PC66                                    0.002122\n",
      "diag_PC67                                    0.002122\n",
      "diag_PC68                                    0.002122\n",
      "diag_PC65                                    0.002122\n",
      "diag_PC64                                    0.002122\n",
      "diag_PC63                                    0.002122\n",
      "diag_PC70                                    0.002122\n",
      "diag_PC62                                    0.002122\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {naive_bayes_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {naive_bayes_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {naive_bayes_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {naive_bayes_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {naive_bayes_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {naive_bayes_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {naive_bayes_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {naive_bayes_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {naive_bayes_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = naive_bayes_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Naive Bayes using log likelihood\n",
    "print(f\"\\nMost Important Features:\")\n",
    "model = naive_bayes_results[\"results\"][0][\"model\"]\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Get log likelihood for each feature\n",
    "log_likelihood = model.get_log_likelihood(train_X_first_fold)\n",
    "\n",
    "# Calculate feature importance as the difference in log likelihood between classes\n",
    "# Positive values indicate features that favor class 1 (readmission)\n",
    "feature_importance_values = log_likelihood[:, 1] - log_likelihood[:, 0]\n",
    "\n",
    "# Create pandas Series for consistent format\n",
    "feature_importance = pd.Series(feature_importance_values, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d868c9c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62324bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear SVM ===\n",
      "Training SGDClassifier with hinge loss (Linear SVM)...\n",
      "Trained fold 0 in 6.76s\n",
      "Trained fold 1 in 4.22s\n",
      "Trained fold 2 in 3.51s\n",
      "Trained fold 3 in 4.30s\n",
      "Trained fold 4 in 5.33s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Linear SVM ===\")\n",
    "\n",
    "# Train SGDClassifier with hinge loss (equivalent to SVM) using cv_evaluate_model format\n",
    "print(\"Training SGDClassifier with hinge loss (Linear SVM)...\")\n",
    "\n",
    "linear_svm_results = cv_evaluate_model(\n",
    "    lambda: SGDClassifier(\n",
    "        loss='hinge',           # Hinge loss = SVM\n",
    "        max_iter=1000,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        learning_rate='optimal'\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77ff1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Model Performance Analysis\n",
      "\n",
      "Average training time: 4.82s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6536\n",
      "Avg Precision:  0.1778\n",
      "Avg Recall:     0.5800\n",
      "Avg F1:         0.2720\n",
      "Avg ROC AUC:    0.6686\n",
      "Avg PR AUC:     0.2069\n",
      "Overfitting Accuracy: 0.0041\n",
      "Overfitting AUC: 0.0174\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12496           5613           \n",
      "                Readmit         1056            1269           \n",
      "\n",
      "Most Important Features (Std-Adjusted):\n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.494645\n",
      "discharge_disposition_id_11   -0.303617\n",
      "discharge_disposition_id_22    0.233930\n",
      "discharge_disposition_id_3     0.227592\n",
      "discharge_disposition_id_5     0.158642\n",
      "diag_PC7                       0.128290\n",
      "diag_PC1                       0.123597\n",
      "discharge_disposition_id_2     0.119308\n",
      "diag_PC19                      0.112456\n",
      "age_[80-90)                    0.107065\n",
      "discharge_disposition_id_6     0.099763\n",
      "admission_source_id_17        -0.098744\n",
      "gender_Male x age_[60-70)      0.081875\n",
      "discharge_disposition_id_18    0.076018\n",
      "time_in_hospital               0.075324\n",
      "age_[60-70)                    0.072510\n",
      "diag_PC40                      0.065571\n",
      "discharge_disposition_id_28    0.062264\n",
      "diag_PC35                      0.061129\n",
      "A1Cresult_>8                  -0.060611\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {linear_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {linear_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {linear_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {linear_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {linear_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {linear_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {linear_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {linear_svm_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {linear_svm_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = linear_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Linear SVM (adjusted by standard deviation)\n",
    "print(f\"\\nMost Important Features (Std-Adjusted):\")\n",
    "\n",
    "# Get the first fold data for standard deviation calculation\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Calculate standard deviation for each feature\n",
    "feature_std = np.std(train_X_first_fold, axis=0)\n",
    "\n",
    "# Get raw coefficients\n",
    "raw_coef = linear_svm_results[\"results\"][0][\"model\"].coef_[0]\n",
    "\n",
    "# Calculate adjusted feature importance: coefficient * std_dev (preserve direction)\n",
    "feature_importance_with_direction = raw_coef * feature_std\n",
    "\n",
    "# Create pandas Series for consistent format with baseline\n",
    "feature_importance = pd.Series(feature_importance_with_direction, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d469185",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1969dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RFF Kernel SVM (Random Fourier Features) ===\n",
      "Training RFF with SGD hinge loss (RBF kernel approximation)...\n",
      "Trained fold 0 in 21.36s\n",
      "Trained fold 1 in 30.92s\n",
      "Trained fold 2 in 22.53s\n",
      "Trained fold 3 in 22.52s\n",
      "Trained fold 4 in 21.34s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RFF Kernel SVM (Random Fourier Features) ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "gamma = 0.01  # RBF kernel parameter\n",
    "n_components = 3000  # Number of random features\n",
    "\n",
    "# Train RFF with SGD hinge loss (approximation to RBF kernel SVM)\n",
    "print(\"Training RFF with SGD hinge loss (RBF kernel approximation)...\")\n",
    "\n",
    "rff_svm_results = cv_evaluate_model(\n",
    "    lambda: Pipeline([\n",
    "        ('rff', RBFSampler(gamma=gamma, n_components=n_components, random_state=seed)),\n",
    "        ('sgd', SGDClassifier(\n",
    "            loss='hinge',\n",
    "            max_iter=1000,\n",
    "            random_state=seed,\n",
    "            class_weight='balanced',\n",
    "            learning_rate='optimal'\n",
    "        ))\n",
    "    ]),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1996ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF SVM Model Performance Analysis\n",
      "\n",
      "Average training time: 23.74s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6600\n",
      "Avg Precision:  0.1783\n",
      "Avg Recall:     0.5626\n",
      "Avg F1:         0.2701\n",
      "Avg ROC AUC:    0.6665\n",
      "Avg PR AUC:     0.2006\n",
      "Overfitting Accuracy: 0.0027\n",
      "Overfitting AUC: 0.0103\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11778           6331           \n",
      "                Readmit         990             1335           \n",
      "Note: RFF approximates RBF kernel with random Fourier features for faster training\n"
     ]
    }
   ],
   "source": [
    "print(\"RFF SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {rff_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {rff_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {rff_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {rff_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {rff_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {rff_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {rff_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {rff_svm_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {rff_svm_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = rff_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "print(\"Note: RFF approximates RBF kernel with random Fourier features for faster training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646cf1e8",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209ae27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "Training Decision Tree with balanced classes...\n",
      "Trained fold 0 in 11.60s\n",
      "Trained fold 1 in 10.85s\n",
      "Trained fold 2 in 11.32s\n",
      "Trained fold 3 in 10.53s\n",
      "Trained fold 4 in 10.66s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Decision Tree ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "max_depth = 7  # Will be optimized in finetuning\n",
    "min_samples_split = 200  # Will be optimized in finetuning\n",
    "min_samples_leaf = 100  # Will be optimized in finetuning\n",
    "max_features = None  # Will be optimized in finetuning\n",
    "\n",
    "# Train Decision Tree with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Decision Tree with balanced classes...\")\n",
    "\n",
    "decision_tree_results = cv_evaluate_model(\n",
    "    lambda: DecisionTreeClassifier(\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "461ad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance Analysis\n",
      "\n",
      "Average training time: 10.99s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6566\n",
      "Avg Precision:  0.1731\n",
      "Avg Recall:     0.5489\n",
      "Avg F1:         0.2631\n",
      "Avg ROC AUC:    0.6451\n",
      "Avg PR AUC:     0.1984\n",
      "Overfitting Accuracy: 0.0068\n",
      "Overfitting AUC: 0.0245\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12318           5791           \n",
      "                Readmit         1084            1241           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.494880\n",
      "discharge_disposition_id_22    0.100785\n",
      "discharge_disposition_id_11    0.085955\n",
      "discharge_disposition_id_3     0.063906\n",
      "diag_PC1                       0.050782\n",
      "discharge_disposition_id_5     0.032369\n",
      "diag_PC128                     0.015816\n",
      "number_diagnoses               0.013297\n",
      "diag_PC32                      0.009643\n",
      "diag_PC43                      0.009213\n",
      "diag_PC59                      0.008929\n",
      "discharge_disposition_id_2     0.007524\n",
      "diag_PC143                     0.007522\n",
      "diag_PC31                      0.006390\n",
      "diag_PC10                      0.006103\n",
      "diag_PC44                      0.005756\n",
      "diag_PC83                      0.005077\n",
      "diag_PC87                      0.004617\n",
      "diag_PC20                      0.004575\n",
      "diag_PC168                     0.004269\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {decision_tree_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {decision_tree_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {decision_tree_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {decision_tree_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {decision_tree_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {decision_tree_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {decision_tree_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {decision_tree_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {decision_tree_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = decision_tree_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(decision_tree_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa0211",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e765764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Training Random Forest with balanced classes...\n",
      "Trained fold 0 in 14.57s\n",
      "Trained fold 1 in 12.81s\n",
      "Trained fold 2 in 12.09s\n",
      "Trained fold 3 in 12.21s\n",
      "Trained fold 4 in 14.78s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Random Forest ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 200  # Will be optimized in finetuning\n",
    "max_depth = 7  # Will be optimized in finetuning\n",
    "min_samples_split = 200  # Will be optimized in finetuning\n",
    "min_samples_leaf = 100  # Will be optimized in finetuning\n",
    "max_features = 'sqrt'  # Will be optimized in finetuning\n",
    "\n",
    "# Train Random Forest with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Random Forest with balanced classes...\")\n",
    "\n",
    "random_forest_results = cv_evaluate_model(\n",
    "    lambda: RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight='balanced',\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "719763bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance Analysis\n",
      "\n",
      "Average training time: 13.29\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6574\n",
      "Avg Precision:  0.1708\n",
      "Avg Recall:     0.5370\n",
      "Avg F1:         0.2591\n",
      "Avg ROC AUC:    0.6519\n",
      "Avg PR AUC:     0.1910\n",
      "Overfitting Accuracy: 0.0185\n",
      "Overfitting AUC: 0.0601\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11998           6111           \n",
      "                Readmit         1048            1277           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.150782\n",
      "discharge_disposition_id_11    0.043483\n",
      "diag_PC1                       0.037378\n",
      "discharge_disposition_id_22    0.036809\n",
      "number_emergency               0.027408\n",
      "number_diagnoses               0.021198\n",
      "diag_PC0                       0.019192\n",
      "num_medications                0.014960\n",
      "diag_PC19                      0.014304\n",
      "diag_PC5                       0.012999\n",
      "time_in_hospital               0.012438\n",
      "diag_PC18                      0.012280\n",
      "discharge_disposition_id_3     0.012259\n",
      "diag_PC7                       0.012208\n",
      "diag_PC27                      0.009141\n",
      "diag_PC16                      0.008700\n",
      "diag_PC68                      0.008167\n",
      "diag_PC143                     0.007277\n",
      "diag_PC72                      0.007175\n",
      "diag_PC74                      0.006641\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {random_forest_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {random_forest_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {random_forest_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {random_forest_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {random_forest_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {random_forest_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {random_forest_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {random_forest_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {random_forest_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = random_forest_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(random_forest_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b3ffe",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6869f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Training XGBoost with balanced classes...\n",
      "Trained fold 0 in 3.30s\n",
      "Trained fold 1 in 3.03s\n",
      "Trained fold 2 in 2.85s\n",
      "Trained fold 3 in 2.91s\n",
      "Trained fold 4 in 2.84s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== XGBoost ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 200  # Will be optimized in finetuning\n",
    "max_depth = 3  # Will be optimized in finetuning\n",
    "learning_rate = 0.1  # Will be optimized in finetuning\n",
    "subsample = 0.8  # Will be optimized in finetuning\n",
    "colsample_bytree = 0.8  # Will be optimized in finetuning\n",
    "\n",
    "# Train XGBoost with balanced classes using cv_evaluate_model format\n",
    "print(\"Training XGBoost with balanced classes...\")\n",
    "\n",
    "xgb_results = cv_evaluate_model(\n",
    "    lambda: xgb.XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        scale_pos_weight=len(train_y_folds[0][train_y_folds[0]==0])/len(train_y_folds[0][train_y_folds[0]==1]),  # Handle class imbalance\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d4af325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance Analysis\n",
      "\n",
      "Average training time: 2.99\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6690\n",
      "Avg Precision:  0.1829\n",
      "Avg Recall:     0.5668\n",
      "Avg F1:         0.2765\n",
      "Avg ROC AUC:    0.6747\n",
      "Avg PR AUC:     0.2208\n",
      "Overfitting Accuracy: 0.0165\n",
      "Overfitting AUC: 0.0575\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12305           5804           \n",
      "                Readmit         996             1329           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.035053\n",
      "discharge_disposition_id_22    0.019119\n",
      "diag_PC1                       0.015644\n",
      "discharge_disposition_id_11    0.014054\n",
      "discharge_disposition_id_3     0.013836\n",
      "number_diagnoses               0.008634\n",
      "discharge_disposition_id_5     0.008546\n",
      "diag_PC0                       0.007733\n",
      "number_emergency               0.007637\n",
      "diag_PC45                      0.007046\n",
      "diag_PC7                       0.006701\n",
      "discharge_disposition_id_2     0.006171\n",
      "diag_PC35                      0.006150\n",
      "time_in_hospital               0.006113\n",
      "diag_PC139                     0.005703\n",
      "age_[70-80)                    0.005682\n",
      "discharge_disposition_id_28    0.005679\n",
      "diag_PC117                     0.005678\n",
      "diag_PC94                      0.005642\n",
      "admission_type_id_6            0.005554\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {xgb_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {xgb_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {xgb_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {xgb_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {xgb_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {xgb_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {xgb_results['test_pr_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting Accuracy:':<15} {xgb_results['overfitting_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Overfitting AUC:':<15} {xgb_results['overfitting_auc'][0]:.4f}\")\n",
    "\n",
    "cm = xgb_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(xgb_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc9b04",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc536d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Comparison Table ===\n",
      "\n",
      "Model Performance Comparison:\n",
      "====================================================================================================\n",
      "              Model Training Time (s) Accuracy Precision Recall F1 Score ROC AUC PR AUC Overfitting Acc Overfitting AUC\n",
      "Logistic Regression              7.18   0.6582    0.1800 0.5801   0.2747  0.6745 0.2111          0.0037          0.0168\n",
      "        Naive Bayes              1.02   0.6199    0.1446 0.4888   0.2231  0.5878 0.1544          0.0026          0.0153\n",
      "         Linear SVM              4.82   0.6536    0.1778 0.5800   0.2720  0.6686 0.2069          0.0041          0.0174\n",
      "         Kernel SVM             23.74   0.6600    0.1783 0.5626   0.2701  0.6665 0.2006          0.0027          0.0103\n",
      "      Decision Tree             10.99   0.6566    0.1731 0.5489   0.2631  0.6451 0.1984          0.0068          0.0245\n",
      "      Random Forest             13.29   0.6574    0.1708 0.5370   0.2591  0.6519 0.1910          0.0185          0.0601\n",
      "            XGBoost              2.99   0.6690    0.1829 0.5668   0.2765  0.6747 0.2208          0.0165          0.0575\n",
      "\n",
      "==================================================\n",
      "BEST PERFORMING MODELS:\n",
      "==================================================\n",
      "Accuracy    : XGBoost              (0.6690)\n",
      "Precision   : XGBoost              (0.1829)\n",
      "Recall      : Logistic Regression  (0.5801)\n",
      "F1 Score    : XGBoost              (0.2765)\n",
      "ROC AUC     : XGBoost              (0.6747)\n",
      "PR AUC      : XGBoost              (0.2208)\n",
      "\n",
      "==================================================\n",
      "OVERFITTING ANALYSIS:\n",
      "==================================================\n",
      "Overfitting Acc: Random Forest        (0.0185) - HIGHER IS WORSE\n",
      "Overfitting AUC: Random Forest        (0.0601) - HIGHER IS WORSE\n",
      "\n",
      "==================================================\n",
      "TRAINING TIME ANALYSIS:\n",
      "==================================================\n",
      "Fastest Training: Naive Bayes          (1.02s)\n",
      "Slowest Training: Kernel SVM           (23.74s)\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table with all model results\n",
    "print(\"=== Model Comparison Table ===\")\n",
    "\n",
    "# Collect all results\n",
    "models_data = {\n",
    "    'Logistic Regression': logistic_regression_results,\n",
    "    'Naive Bayes': naive_bayes_results,\n",
    "    'Linear SVM': linear_svm_results,\n",
    "    'Kernel SVM': rff_svm_results,\n",
    "    'Decision Tree': decision_tree_results,\n",
    "    'Random Forest': random_forest_results,\n",
    "    'XGBoost': xgb_results\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for model_name, results in models_data.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Training Time (s)': f\"{results['training_time'][0]:.2f}\",\n",
    "        'Accuracy': f\"{results['test_accuracy'][0]:.4f}\",\n",
    "        'Precision': f\"{results['test_precision_score'][0]:.4f}\",\n",
    "        'Recall': f\"{results['test_recall_score'][0]:.4f}\",\n",
    "        'F1 Score': f\"{results['test_f1'][0]:.4f}\",\n",
    "        'ROC AUC': f\"{results['test_roc_auc'][0]:.4f}\",\n",
    "        'PR AUC': f\"{results['test_pr_auc'][0]:.4f}\",\n",
    "        'Overfitting Acc': f\"{results['overfitting_accuracy'][0]:.4f}\",\n",
    "        'Overfitting AUC': f\"{results['overfitting_auc'][0]:.4f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display the comparison table\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best performing models for each metric\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BEST PERFORMING MODELS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert numeric columns for comparison (excluding the commented row)\n",
    "numeric_data = comparison_df[comparison_df['Model'] != '# RBF SVM (commented out - too slow)'].copy()\n",
    "for col in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC', 'Overfitting Acc', 'Overfitting AUC']:\n",
    "    numeric_data[col] = numeric_data[col].astype(float)\n",
    "\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC']:\n",
    "    best_idx = numeric_data[metric].idxmax()\n",
    "    best_model = numeric_data.loc[best_idx, 'Model']\n",
    "    best_score = numeric_data.loc[best_idx, metric]\n",
    "    print(f\"{metric:<12}: {best_model:<20} ({best_score:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"OVERFITTING ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "# For overfitting, we want the HIGHEST values (most overfitting)\n",
    "for metric in ['Overfitting Acc', 'Overfitting AUC']:\n",
    "    worst_idx = numeric_data[metric].idxmax()  # Use idxmax for overfitting (higher is worse)\n",
    "    worst_model = numeric_data.loc[worst_idx, 'Model']\n",
    "    worst_score = numeric_data.loc[worst_idx, metric]\n",
    "    print(f\"{metric:<12}: {worst_model:<20} ({worst_score:.4f}) - HIGHER IS WORSE\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING TIME ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "fastest_idx = numeric_data['Training Time (s)'].astype(float).idxmin()\n",
    "fastest_model = numeric_data.loc[fastest_idx, 'Model']\n",
    "fastest_time = numeric_data.loc[fastest_idx, 'Training Time (s)']\n",
    "print(f\"Fastest Training: {fastest_model:<20} ({fastest_time}s)\")\n",
    "\n",
    "slowest_idx = numeric_data['Training Time (s)'].astype(float).idxmax()\n",
    "slowest_model = numeric_data.loc[slowest_idx, 'Model']\n",
    "slowest_time = numeric_data.loc[slowest_idx, 'Training Time (s)']\n",
    "print(f\"Slowest Training: {slowest_model:<20} ({slowest_time}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0f59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it5006-group10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
