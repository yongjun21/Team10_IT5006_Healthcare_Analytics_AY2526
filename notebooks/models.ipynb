{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542d3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from classes import MixedNaiveBayes\n",
    "\n",
    "from classes import CustomLogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from helpers import cv_evaluate_model\n",
    "\n",
    "import time\n",
    "\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bf0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "(train_X_folds, train_y_folds, test_X_folds, test_y_folds, feature_names_folds, reverse_map_folds) = pickle.load(open('data/prepared_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa577cb",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b9d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline ===\n",
      "Training Logistic Regression with L1 & L2 regularization...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline ===\")\n",
    "\n",
    "alpha = 5\n",
    "l1_ratio = 0.75\n",
    "\n",
    "# Train Logistic Regression with L1 & L2 regularization\n",
    "print(\"Training Logistic Regression with L1 & L2 regularization...\")\n",
    "\n",
    "logistic_regression_results = cv_evaluate_model(\n",
    "    lambda: CustomLogisticRegression(\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=200,\n",
    "        tol=1e-6,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance Analysis\n",
      "\n",
      "Average training time: 7.72\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6582\n",
      "Avg Precision:  0.1800\n",
      "Avg Recall:     0.5801\n",
      "Avg F1:         0.2747\n",
      "Avg ROC AUC:    0.6745\n",
      "Avg PR AUC:     0.2111\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12089           6020           \n",
      "                Readmit         994             1331           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                  -4.215332\n",
      "discharge_disposition_id_28                   1.689171\n",
      "discharge_disposition_id_15                   1.364386\n",
      "discharge_disposition_id_22                   1.351553\n",
      "discharge_disposition_id_5                    1.030752\n",
      "discharge_disposition_id_13                  -0.809176\n",
      "medical_specialty_Otolaryngology             -0.775223\n",
      "medical_specialty_Pediatrics-Endocrinology   -0.770679\n",
      "medical_specialty_Hematology                  0.749855\n",
      "discharge_disposition_id_9                    0.670702\n",
      "discharge_disposition_id_14                  -0.659517\n",
      "medical_specialty_Hematology/Oncology         0.597548\n",
      "discharge_disposition_id_23                  -0.594647\n",
      "diag_PC173                                   -0.586729\n",
      "race_Other x age_[80-90)                     -0.586537\n",
      "discharge_disposition_id_2                    0.556056\n",
      "race_Asian x age_[70-80)                      0.541512\n",
      "diag_PC129                                   -0.526060\n",
      "diag_PC187                                   -0.514839\n",
      "diag_PC19                                     0.499054\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {logistic_regression_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {logistic_regression_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {logistic_regression_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {logistic_regression_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {logistic_regression_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {logistic_regression_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {logistic_regression_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = logistic_regression_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "feature_importance = pd.Series(logistic_regression_results[\"results\"][0][\"model\"].coef_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0ff8c",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f144e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "Training MixedNaiveBayes with balanced classes...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Naive Bayes ===\")\n",
    "\n",
    "# Train MixedNaiveBayes with balanced classes using cv_evaluate_model format\n",
    "print(\"Training MixedNaiveBayes with balanced classes...\")\n",
    "\n",
    "naive_bayes_results = cv_evaluate_model(\n",
    "    lambda: MixedNaiveBayes(class_weight='balanced'),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance Analysis\n",
      "\n",
      "Average training time: 1.18\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6199\n",
      "Avg Precision:  0.1446\n",
      "Avg Recall:     0.4888\n",
      "Avg F1:         0.2231\n",
      "Avg ROC AUC:    0.5878\n",
      "Avg PR AUC:     0.1544\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      11473           6636           \n",
      "                Readmit         1154            1171           \n",
      "\n",
      "Most Important Features:\n",
      "discharge_disposition_id_11                 -0.065009\n",
      "insulin_yes                                  0.026994\n",
      "admission_source_id_7                        0.017168\n",
      "discharge_disposition_id_22                 -0.010460\n",
      "metformin_yes                               -0.008313\n",
      "age_[50-60)                                 -0.005458\n",
      "medical_specialty_Cardiology                -0.003493\n",
      "age_[70-80)                                  0.003474\n",
      "admission_type_id_3                         -0.003086\n",
      "discharge_disposition_id_5                  -0.002910\n",
      "age_[80-90)                                  0.002342\n",
      "medical_specialty_ObstetricsandGynecology   -0.002163\n",
      "diag_PC66                                    0.002122\n",
      "diag_PC67                                    0.002122\n",
      "diag_PC68                                    0.002122\n",
      "diag_PC65                                    0.002122\n",
      "diag_PC64                                    0.002122\n",
      "diag_PC63                                    0.002122\n",
      "diag_PC70                                    0.002122\n",
      "diag_PC62                                    0.002122\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {naive_bayes_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {naive_bayes_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {naive_bayes_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {naive_bayes_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {naive_bayes_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {naive_bayes_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {naive_bayes_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = naive_bayes_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Naive Bayes using log likelihood\n",
    "print(f\"\\nMost Important Features:\")\n",
    "model = naive_bayes_results[\"results\"][0][\"model\"]\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Get log likelihood for each feature\n",
    "log_likelihood = model.get_log_likelihood(train_X_first_fold)\n",
    "\n",
    "# Calculate feature importance as the difference in log likelihood between classes\n",
    "# Positive values indicate features that favor class 1 (readmission)\n",
    "feature_importance_values = log_likelihood[:, 1] - log_likelihood[:, 0]\n",
    "\n",
    "# Create pandas Series for consistent format\n",
    "feature_importance = pd.Series(feature_importance_values, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d868c9c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62324bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear SVM ===\n",
      "Training SGDClassifier with hinge loss (Linear SVM)...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Linear SVM ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "max_iter = 1000  # Will be optimized in finetuning\n",
    "learning_rate = 'optimal'  # Will be optimized in finetuning\n",
    "\n",
    "# Train SGDClassifier with hinge loss (equivalent to SVM) using cv_evaluate_model format\n",
    "print(\"Training SGDClassifier with hinge loss (Linear SVM)...\")\n",
    "\n",
    "linear_svm_results = cv_evaluate_model(\n",
    "    lambda: SGDClassifier(\n",
    "        loss='hinge',           # Hinge loss = SVM\n",
    "        max_iter=max_iter,\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        learning_rate=learning_rate\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77ff1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Model Performance Analysis\n",
      "\n",
      "Average training time: 5.32s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6536\n",
      "Avg Precision:  0.1778\n",
      "Avg Recall:     0.5800\n",
      "Avg F1:         0.2720\n",
      "Avg ROC AUC:    0.6686\n",
      "Avg PR AUC:     0.2069\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      12496           5613           \n",
      "                Readmit         1056            1269           \n",
      "\n",
      "Most Important Features (Std-Adjusted):\n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.494645\n",
      "discharge_disposition_id_11   -0.303617\n",
      "discharge_disposition_id_22    0.233930\n",
      "discharge_disposition_id_3     0.227592\n",
      "discharge_disposition_id_5     0.158642\n",
      "diag_PC7                       0.128290\n",
      "diag_PC1                       0.123597\n",
      "discharge_disposition_id_2     0.119308\n",
      "diag_PC19                      0.112456\n",
      "age_[80-90)                    0.107065\n",
      "discharge_disposition_id_6     0.099763\n",
      "admission_source_id_17        -0.098744\n",
      "gender_Male x age_[60-70)      0.081875\n",
      "discharge_disposition_id_18    0.076018\n",
      "time_in_hospital               0.075324\n",
      "age_[60-70)                    0.072510\n",
      "diag_PC40                      0.065571\n",
      "discharge_disposition_id_28    0.062264\n",
      "diag_PC35                      0.061129\n",
      "A1Cresult_>8                  -0.060611\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {linear_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {linear_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {linear_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {linear_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {linear_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {linear_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {linear_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = linear_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis for Linear SVM (adjusted by standard deviation)\n",
    "print(f\"\\nMost Important Features (Std-Adjusted):\")\n",
    "\n",
    "# Get the first fold data for standard deviation calculation\n",
    "train_X_first_fold = train_X_folds[0]\n",
    "feature_names_first_fold = feature_names_folds[0]\n",
    "\n",
    "# Calculate standard deviation for each feature\n",
    "feature_std = np.std(train_X_first_fold, axis=0)\n",
    "\n",
    "# Get raw coefficients\n",
    "raw_coef = linear_svm_results[\"results\"][0][\"model\"].coef_[0]\n",
    "\n",
    "# Calculate adjusted feature importance: coefficient * std_dev (preserve direction)\n",
    "feature_importance_with_direction = raw_coef * feature_std\n",
    "\n",
    "# Create pandas Series for consistent format with baseline\n",
    "feature_importance = pd.Series(feature_importance_with_direction, index=feature_names_first_fold)\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "\n",
    "print(f\"\\nMost Important Features:\")\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d469185",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1969dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RBF Kernel SVM ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "C = 1.0  # Will be optimized in finetuning\n",
    "gamma = 'scale'  # Will be optimized in finetuning\n",
    "\n",
    "# Train RBF SVM with balanced classes using cv_evaluate_model format\n",
    "print(\"Training RBF SVM with balanced classes...\")\n",
    "\n",
    "rbf_svm_results = cv_evaluate_model(\n",
    "    lambda: SVC(\n",
    "        kernel='rbf',\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        class_weight='balanced',\n",
    "        random_state=seed\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.decision_function(X)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RBF SVM Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {rbf_svm_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {rbf_svm_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {rbf_svm_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {rbf_svm_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {rbf_svm_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {rbf_svm_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {rbf_svm_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = rbf_svm_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646cf1e8",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209ae27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "Training Decision Tree with balanced classes...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Decision Tree ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "max_depth = 10  # Will be optimized in finetuning\n",
    "min_samples_split = 20  # Will be optimized in finetuning\n",
    "min_samples_leaf = 10  # Will be optimized in finetuning\n",
    "max_features = 'sqrt'  # Will be optimized in finetuning\n",
    "\n",
    "# Train Decision Tree with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Decision Tree with balanced classes...\")\n",
    "\n",
    "decision_tree_results = cv_evaluate_model(\n",
    "    lambda: DecisionTreeClassifier(\n",
    "        random_state=seed,\n",
    "        class_weight='balanced',\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "461ad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Performance Analysis\n",
      "\n",
      "Average training time: 0.78s\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.5978\n",
      "Avg Precision:  0.1451\n",
      "Avg Recall:     0.5261\n",
      "Avg F1:         0.2262\n",
      "Avg ROC AUC:    0.5859\n",
      "Avg PR AUC:     0.1530\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      9003            9106           \n",
      "                Readmit         891             1434           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.144029\n",
      "discharge_disposition_id_11    0.039930\n",
      "diag_PC5                       0.029617\n",
      "number_diagnoses               0.025843\n",
      "diag_PC143                     0.020421\n",
      "diag_PC88                      0.015053\n",
      "diag_PC12                      0.012598\n",
      "diag_PC54                      0.012260\n",
      "diag_PC74                      0.011164\n",
      "diag_PC26                      0.010982\n",
      "diag_PC155                     0.010584\n",
      "diag_PC66                      0.010102\n",
      "diag_PC142                     0.009905\n",
      "diag_PC105                     0.009890\n",
      "diag_PC160                     0.009676\n",
      "diag_PC184                     0.009272\n",
      "diag_PC166                     0.009209\n",
      "diag_PC131                     0.009183\n",
      "diag_PC60                      0.008596\n",
      "diag_PC51                      0.008470\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {decision_tree_results['training_time'][0]:.2f}s\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {decision_tree_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {decision_tree_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {decision_tree_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {decision_tree_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {decision_tree_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {decision_tree_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = decision_tree_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(decision_tree_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa0211",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e765764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Training Random Forest with balanced classes...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Random Forest ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 100  # Will be optimized in finetuning\n",
    "max_depth = 10  # Will be optimized in finetuning\n",
    "min_samples_split = 20  # Will be optimized in finetuning\n",
    "min_samples_leaf = 10  # Will be optimized in finetuning\n",
    "max_features = 'sqrt'  # Will be optimized in finetuning\n",
    "\n",
    "# Train Random Forest with balanced classes using cv_evaluate_model format\n",
    "print(\"Training Random Forest with balanced classes...\")\n",
    "\n",
    "random_forest_results = cv_evaluate_model(\n",
    "    lambda: RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight='balanced',\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "719763bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance Analysis\n",
      "\n",
      "Average training time: 9.51\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.7468\n",
      "Avg Precision:  0.1870\n",
      "Avg Recall:     0.3790\n",
      "Avg F1:         0.2504\n",
      "Avg ROC AUC:    0.6408\n",
      "Avg PR AUC:     0.1833\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      14135           3974           \n",
      "                Readmit         1412            913            \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient               0.096771\n",
      "discharge_disposition_id_11    0.022389\n",
      "discharge_disposition_id_22    0.020103\n",
      "diag_PC1                       0.017991\n",
      "number_emergency               0.016362\n",
      "number_diagnoses               0.011200\n",
      "num_medications                0.011043\n",
      "diag_PC5                       0.010119\n",
      "diag_PC0                       0.010033\n",
      "time_in_hospital               0.008833\n",
      "diag_PC19                      0.008094\n",
      "discharge_disposition_id_3     0.007670\n",
      "diag_PC68                      0.007475\n",
      "diag_PC7                       0.007227\n",
      "diag_PC18                      0.007151\n",
      "diag_PC72                      0.006849\n",
      "diag_PC16                      0.006741\n",
      "diag_PC143                     0.006446\n",
      "diag_PC27                      0.006402\n",
      "diag_PC31                      0.005804\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {random_forest_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {random_forest_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {random_forest_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {random_forest_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {random_forest_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {random_forest_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {random_forest_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = random_forest_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(random_forest_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ce7cf",
   "metadata": {},
   "source": [
    "### Optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6869f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Training XGBoost with balanced classes...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== XGBoost ===\")\n",
    "\n",
    "# Tunable parameters\n",
    "n_estimators = 100  # Will be optimized in finetuning\n",
    "max_depth = 6  # Will be optimized in finetuning\n",
    "learning_rate = 0.1  # Will be optimized in finetuning\n",
    "subsample = 0.8  # Will be optimized in finetuning\n",
    "colsample_bytree = 0.8  # Will be optimized in finetuning\n",
    "\n",
    "# Train XGBoost with balanced classes using cv_evaluate_model format\n",
    "print(\"Training XGBoost with balanced classes...\")\n",
    "\n",
    "xgb_results = cv_evaluate_model(\n",
    "    lambda: xgb.XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        scale_pos_weight=len(train_y_folds[0][train_y_folds[0]==0])/len(train_y_folds[0][train_y_folds[0]==1]),  # Handle class imbalance\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    train_X_folds,\n",
    "    train_y_folds,\n",
    "    test_X_folds,\n",
    "    test_y_folds,\n",
    "    get_decision_score=lambda model, X: model.predict_proba(X)[:, 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d4af325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance Analysis\n",
      "\n",
      "Average training time: 2.70\n",
      "\n",
      "Metrics\n",
      "Avg Accuracy:   0.6989\n",
      "Avg Precision:  0.1860\n",
      "Avg Recall:     0.5023\n",
      "Avg F1:         0.2714\n",
      "Avg ROC AUC:    0.6642\n",
      "Avg PR AUC:     0.2125\n",
      "\n",
      "Confusion Matrix\n",
      "                Predicted       No Readmit      Readmit        \n",
      "Actual          No Readmit      13061           5048           \n",
      "                Readmit         1141            1184           \n",
      "\n",
      "Most Important Features:\n",
      "number_inpatient                            0.024820\n",
      "discharge_disposition_id_22                 0.018417\n",
      "discharge_disposition_id_11                 0.013670\n",
      "discharge_disposition_id_3                  0.011549\n",
      "diag_PC1                                    0.009219\n",
      "discharge_disposition_id_5                  0.008564\n",
      "number_emergency                            0.008168\n",
      "discharge_disposition_id_2                  0.005635\n",
      "diag_PC140                                  0.005380\n",
      "discharge_disposition_id_28                 0.005274\n",
      "number_diagnoses                            0.005094\n",
      "diag_PC43                                   0.004963\n",
      "diag_PC35                                   0.004909\n",
      "age_[50-60)                                 0.004881\n",
      "diag_PC28                                   0.004878\n",
      "diag_PC19                                   0.004838\n",
      "discharge_disposition_id_6                  0.004693\n",
      "medical_specialty_Family/GeneralPractice    0.004657\n",
      "metformin_yes                               0.004547\n",
      "diag_PC152                                  0.004535\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Model Performance Analysis\")\n",
    "\n",
    "print(\n",
    "    f\"\\nAverage training time: {xgb_results['training_time'][0]:.2f}\")\n",
    "\n",
    "print(\"\\nMetrics\")\n",
    "print(\n",
    "    f\"{'Avg Accuracy:':<15} {xgb_results['test_accuracy'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Precision:':<15} {xgb_results['test_precision_score'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg Recall:':<15} {xgb_results['test_recall_score'][0]:.4f}\")\n",
    "print(f\"{'Avg F1:':<15} {xgb_results['test_f1'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg ROC AUC:':<15} {xgb_results['test_roc_auc'][0]:.4f}\")\n",
    "print(\n",
    "    f\"{'Avg PR AUC:':<15} {xgb_results['test_pr_auc'][0]:.4f}\")\n",
    "\n",
    "cm = xgb_results[\"results\"][0][\"test_cm\"]\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(f\"{'':<15} {'Predicted':<15} {'No Readmit':<15} {'Readmit':<15}\")\n",
    "print(f\"{'Actual':<15} {'No Readmit':<15} {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"{'':<15} {'Readmit':<15} {cm[1,0]:<15} {cm[1,1]:<15}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(f\"\\nMost Important Features:\")\n",
    "feature_importance = pd.Series(xgb_results[\"results\"][0][\"model\"].feature_importances_, index=feature_names_folds[0])\n",
    "feature_importance = feature_importance[feature_importance.abs().sort_values(ascending=False).index]\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc9b04",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc536d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Comparison Table ===\n",
      "\n",
      "Model Performance Comparison:\n",
      "====================================================================================================\n",
      "                               Model Training Time (s) Accuracy Precision Recall F1 Score ROC AUC PR AUC\n",
      "                 Logistic Regression              7.72   0.6582    0.1800 0.5801   0.2747  0.6745 0.2111\n",
      "                         Naive Bayes              1.18   0.6199    0.1446 0.4888   0.2231  0.5878 0.1544\n",
      "                          Linear SVM              5.32   0.6536    0.1778 0.5800   0.2720  0.6686 0.2069\n",
      "                       Decision Tree              0.78   0.5978    0.1451 0.5261   0.2262  0.5859 0.1530\n",
      "                       Random Forest              9.51   0.7468    0.1870 0.3790   0.2504  0.6408 0.1833\n",
      "                             XGBoost              2.70   0.6989    0.1860 0.5023   0.2714  0.6642 0.2125\n",
      "# RBF SVM (commented out - too slow)               N/A      N/A       N/A    N/A      N/A     N/A    N/A\n",
      "\n",
      "==================================================\n",
      "BEST PERFORMING MODELS:\n",
      "==================================================\n",
      "Accuracy    : Random Forest        (0.7468)\n",
      "Precision   : Random Forest        (0.1870)\n",
      "Recall      : Logistic Regression  (0.5801)\n",
      "F1 Score    : Logistic Regression  (0.2747)\n",
      "ROC AUC     : Logistic Regression  (0.6745)\n",
      "PR AUC      : XGBoost              (0.2125)\n",
      "\n",
      "==================================================\n",
      "TRAINING TIME ANALYSIS:\n",
      "==================================================\n",
      "Fastest Training: Decision Tree        (0.78s)\n",
      "Slowest Training: Random Forest        (9.51s)\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table with all model results\n",
    "print(\"=== Model Comparison Table ===\")\n",
    "\n",
    "# Collect all results\n",
    "models_data = {\n",
    "    'Logistic Regression': logistic_regression_results,\n",
    "    'Naive Bayes': naive_bayes_results,\n",
    "    'Linear SVM': linear_svm_results,\n",
    "    # 'RBF SVM': rbf_svm_results,  # Commented out - takes too long to run\n",
    "    'Decision Tree': decision_tree_results,\n",
    "    'Random Forest': random_forest_results,\n",
    "    'XGBoost': xgb_results\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for model_name, results in models_data.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Training Time (s)': f\"{results['training_time'][0]:.2f}\",\n",
    "        'Accuracy': f\"{results['test_accuracy'][0]:.4f}\",\n",
    "        'Precision': f\"{results['test_precision_score'][0]:.4f}\",\n",
    "        'Recall': f\"{results['test_recall_score'][0]:.4f}\",\n",
    "        'F1 Score': f\"{results['test_f1'][0]:.4f}\",\n",
    "        'ROC AUC': f\"{results['test_roc_auc'][0]:.4f}\",\n",
    "        'PR AUC': f\"{results['test_pr_auc'][0]:.4f}\"\n",
    "    })\n",
    "\n",
    "# Add commented out RBF SVM row\n",
    "comparison_data.append({\n",
    "    'Model': '# RBF SVM (commented out - too slow)',\n",
    "    'Training Time (s)': 'N/A',\n",
    "    'Accuracy': 'N/A',\n",
    "    'Precision': 'N/A',\n",
    "    'Recall': 'N/A',\n",
    "    'F1 Score': 'N/A',\n",
    "    'ROC AUC': 'N/A',\n",
    "    'PR AUC': 'N/A'\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display the comparison table\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best performing models for each metric\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BEST PERFORMING MODELS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert numeric columns for comparison (excluding the commented row)\n",
    "numeric_data = comparison_df[comparison_df['Model'] != '# RBF SVM (commented out - too slow)'].copy()\n",
    "for col in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC']:\n",
    "    numeric_data[col] = numeric_data[col].astype(float)\n",
    "\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'PR AUC']:\n",
    "    best_idx = numeric_data[metric].idxmax()\n",
    "    best_model = numeric_data.loc[best_idx, 'Model']\n",
    "    best_score = numeric_data.loc[best_idx, metric]\n",
    "    print(f\"{metric:<12}: {best_model:<20} ({best_score:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING TIME ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "fastest_idx = numeric_data['Training Time (s)'].astype(float).idxmin()\n",
    "fastest_model = numeric_data.loc[fastest_idx, 'Model']\n",
    "fastest_time = numeric_data.loc[fastest_idx, 'Training Time (s)']\n",
    "print(f\"Fastest Training: {fastest_model:<20} ({fastest_time}s)\")\n",
    "\n",
    "slowest_idx = numeric_data['Training Time (s)'].astype(float).idxmax()\n",
    "slowest_model = numeric_data.loc[slowest_idx, 'Model']\n",
    "slowest_time = numeric_data.loc[slowest_idx, 'Training Time (s)']\n",
    "print(f\"Slowest Training: {slowest_model:<20} ({slowest_time}s)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it5006-group10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
